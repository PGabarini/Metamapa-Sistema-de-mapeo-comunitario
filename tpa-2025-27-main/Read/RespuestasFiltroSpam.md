Respuestas A Preguntas de Detector de Spam
==========================================

# ¿Cómo se podría implementar un filtro de spam sin recurrir a servicios externos?

Para implementar un filtro de spam propio, podría contarse con un corpus de datos de ejemplo y realizar la vectorizacion y categorizacion de los mensajes en spam / no spam con código propio sin necesidad de utilizar servicios ni bibliotecas externas.

Para ello decidimos hacerlo de la siguiente manera: Se aplica un proceso de vectorizacion de texto (llevar el texto a una repesentacion numerica dentro de un espacio vectorial) siguiendo el algoritmo TF-IDF para asignar a cada palabra dentro del texto un puntaje numerico que mide su importancia dentro del mismo. Luego, tras el proceso de vectorizacion se pasa a una etapa de clasificacion, para la cual previamente se tiene vectorizado un corpus de datos de ejemplo que viene etiquetado. De esa forma, podemos inferir si un mensaje es spam si "se parece" a otros mensajes que ya conocemos como spam. Para hacer esta clasficacion se utiliza el metodo KNN que consiste en, dado un conjunto de puntos categorizados en un espacio vectorial, asignarle a un nuevo punto, que queremos clasificar, la categoria correspondiente a la mayoria de los k puntos (vecinos) mas cercanos.

A nivel tecnico, se decidio usar el metodo TF-IDF para ponderar la importancia de las palabras en un texto ya que evalua la frecuencia de las mismas en el texto pero compensa penalizando a las palabras que son comunes en todos los textos dando un buen resultado para diferenciar palabras importantes de palabras que no lo son. Para la parte de clasificacion se decidio usar el metodo KNN por una cuestion de simplicidad de implementacion ya que es un detector basico, pero podria ser cambiado por otro mas efectivo en proximas iteraciones. Adicionalmente, podria pensarse en otro tipo de clasificadores, como uno probabilitisco, que no solo categorice sino que de un estimado de la probabilidad de cada categoria.

Si se decidiera a futuro mantener el detector propio, la mayor mejoria vendria de ampliar y curar el corpus de datos de ejemplo pudiendo incluso cruzar ejemplos curados (etiquetados por un administrador, por ejemplo) con otras instancias de Metamapa,
para generar una suerte de "repositorio de ejemplos de spam en solicitudes a metamapa" general, aplicando la idea de inteligencia colectiva ahora entre instancias de Metamapa.

# ¿Cómo se podría implementar un filtro de spam en base a consumir servicios externos en la nube? 

Para implementar un filtro basado en servicios almacenados en la nube implicaría tener un cliente propio capaz de conectarse a la API expuesta por el servicio para poder, por ejemplo, enviarle los mensajes que se deseen clasificar y obtener la respuesta correspondiente. Esto sería bastante similar a lo que hicimos en la fuente Proxy MetaMapa, la cual se conecta con una API externa para pedir los hechos. Esta implementación también incluiría los mecanimos necesarios para realizar los requests ante la llegada de cada solicitud, esperar la respuesta y actuar en consecunecia. De esta manera, la clasificación sería dependiente de los tiempos de respuesta de la API. 

# ¿Qué consecuencias desde el punto de vista de costos y seguridad de datos traería?

La idea de utilizar basado en servicios externos traería conseciencias relacionadas con la seguridad de los datos y podria resultar contraproducente debido a la especificidad de la tarea, ademas de agregar dependencias externas que pueden no ser necesarias y que atarian el correcto funcionamiento de nuestro sistema al correcto funcionamiento y mantencion de sistemas externos, sumado a la implicancia de una potencial serie de costos asociados al uso del servicio sobre los cuales no tenemos control. Esto es, si el servicio externo aumentase sus precios estaríamos atados a seguirlos pagando para mantener el funcionamiento de nuestro sistema, o estar obligado a refactorizar el codigo.

Respecto a la seguridad de los datos, utilizar un servicio completamente externo implicaria exponer todos los mensajes de las solicitudes de los usuarios a un tercero, lo que podria romper un vinculo de privacidad entre Metamapa y los mismos. Ademas, la tarea que se nos propone es muy especifica (eliminar spam de solicitudes de eliminacion de un hecho), diferentes a las mas clasicas filtraciones de spam en emails o SMS, y al estar aplicando tecnicas de aprendizaje supervisado la pertinencia de los datos que se usan como ejemplo es clave en el correcto funcionamiento del modelo; la utilizacion de un modelo propia permite ajustar estos datos de ejemplo como se quiera, actualmente usando uno de demostracion.
